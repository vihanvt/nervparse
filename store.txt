    #this is the file to laod conll files and build the dictionary
    import os
    from collections import Counter
    from torch.utils.data import Dataset, DataLoader
    import torch

    def load_conll(file_path):
        """Loads data from a CONLL-U file.

        Args:
            file_path (str): The path to the CONLL-U file.

        Returns:
            list: A list of dictionaries, where each dictionary represents a sentence.
                Each sentence dictionary contains 'word', 'pos', 'head', and 'label' lists.
        """
        sentences = []
        file_path=r"C:\Users\VIHAN\Desktop\DL\NLP\ndpassignment3\data\train.conll"
        with open(file_path, 'r', encoding='utf-8') as f:
            word, pos, head, label = [], [], [], []
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split('\t')
                    if len(parts) == 10 and parts[0].isdigit():  # Check for valid CONLL-U line
                        word.append(parts[1])  # Form
                        pos.append(parts[3])   # POS
                        head.append(int(parts[6])) # Head
                        label.append(parts[7])  # Deprel
                elif word: #end of sentence, not a comment
                    sentences.append({'word': word, 'pos': pos, 'head': head, 'label': label})
                    word, pos, head, label = [], [], [], []
        return sentences

    def build_vocab(data, min_freq=2):
        """Builds a vocabulary from the dataset.

        Args:
            data (list): A list of sentences (dictionaries).
            min_freq (int): The minimum frequency for a word to be included in the vocabulary.

        Returns:
            dict: A dictionary mapping words to indices.
        """
        word_counts = Counter()
        pos_counts = Counter()
        label_counts = Counter()
        for sentence in data:
            word_counts.update(sentence['word'])
            pos_counts.update(sentence['pos'])
            label_counts.update(sentence['label'])

        word_vocab = {"<NULL>": 0, "<UNK>": 1, "<ROOT>": 2}
        pos_vocab = {"<NULL>": 0, "<UNK>": 1, "<ROOT>": 2} #root may not need to be here
        label_vocab = {"<NULL>": 0, "<UNK>": 1, "<ROOT>": 2}


        for word, count in word_counts.items():
            if count >= min_freq:
                word_vocab[word] = len(word_vocab)

        for pos, count in pos_counts.items():
                pos_vocab[pos] = len(pos_vocab)

        for label, count in label_counts.items():
                label_vocab[label] = len(label_vocab)

        return word_vocab, pos_vocab, label_vocab

    class DependencyDataset(Dataset):
        def __init__(self, data, word_vocab, pos_vocab, label_vocab, parser):
            self.data = data
            self.word_vocab = word_vocab
            self.pos_vocab = pos_vocab
            self.label_vocab = label_vocab
            self.parser = parser #for create instance

        def __len__(self):
            return len(self.data)

        def __getitem__(self, idx):
            sentence = self.data[idx]
            #numericalize and convert sentence example into indices
            word = [self.word_vocab["<ROOT>"]] + [self.word_vocab[w] if w in self.word_vocab else self.word_vocab["<UNK>"] for w in sentence['word']]
            pos = [self.pos_vocab["<ROOT>"]] + [self.pos_vocab[p] if p in self.pos_vocab else self.pos_vocab["<UNK>"] for p in sentence['pos']]
            head = [-1] + sentence['head']
            label = [-1] + [self.label_vocab[l] if l in self.label_vocab else -1 for l in sentence['label']]

            example =  {'word': word, 'pos': pos, 'head': head, 'label': label}
            instances = self.parser.create_instances([example]) #instances is of type (feature, legal_label, gold_label)
            # print(instances[0][0])#feature is the first of the tuple inside a list

            features, legal_labels, gold_label = instances[0] #since the parser creates a nested list
            features = torch.tensor(features, dtype=torch.long)
            gold_label = torch.tensor(gold_label, dtype=torch.long)
            return features, gold_label #tensor of (feature,gold)